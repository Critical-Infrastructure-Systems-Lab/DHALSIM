# Generated from subcatchments.g4 by ANTLR 4.9.2
from antlr4 import *
from io import StringIO
import sys
if sys.version_info[1] > 5:
    from typing import TextIO
else:
    from typing.io import TextIO



def serializedATN():
    with StringIO() as buf:
        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\2\r")
        buf.write("\177\b\1\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t")
        buf.write("\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\3\2\6\2\33")
        buf.write("\n\2\r\2\16\2\34\3\3\7\3 \n\3\f\3\16\3#\13\3\3\3\7\3&")
        buf.write("\n\3\f\3\16\3)\13\3\3\3\6\3,\n\3\r\3\16\3-\3\4\6\4\61")
        buf.write("\n\4\r\4\16\4\62\3\5\3\5\7\5\67\n\5\f\5\16\5:\13\5\3\6")
        buf.write("\3\6\3\6\3\6\3\6\3\6\3\6\3\6\3\6\3\6\3\6\3\7\7\7H\n\7")
        buf.write("\f\7\16\7K\13\7\3\7\3\7\3\7\3\7\3\b\3\b\3\b\3\b\7\bU\n")
        buf.write("\b\f\b\16\bX\13\b\3\b\3\b\3\t\3\t\7\t^\n\t\f\t\16\ta\13")
        buf.write("\t\3\t\3\t\3\t\3\t\3\n\3\n\7\ni\n\n\f\n\16\nl\13\n\3\n")
        buf.write("\3\n\3\n\3\n\3\13\6\13s\n\13\r\13\16\13t\3\13\3\13\3\f")
        buf.write("\6\fz\n\f\r\f\16\f{\3\f\3\f\78IV_j\2\r\3\3\5\4\7\5\t\6")
        buf.write("\13\7\r\b\17\t\21\n\23\13\25\f\27\r\3\2\7\3\2\62;\6\2")
        buf.write("\62;C\\aac|\3\2C\\\3\2\f\f\5\2\13\f\17\17\"\"\2\u008a")
        buf.write("\2\3\3\2\2\2\2\5\3\2\2\2\2\7\3\2\2\2\2\t\3\2\2\2\2\13")
        buf.write("\3\2\2\2\2\r\3\2\2\2\2\17\3\2\2\2\2\21\3\2\2\2\2\23\3")
        buf.write("\2\2\2\2\25\3\2\2\2\2\27\3\2\2\2\3\32\3\2\2\2\5!\3\2\2")
        buf.write("\2\7\60\3\2\2\2\t\64\3\2\2\2\13;\3\2\2\2\rI\3\2\2\2\17")
        buf.write("P\3\2\2\2\21[\3\2\2\2\23f\3\2\2\2\25r\3\2\2\2\27y\3\2")
        buf.write("\2\2\31\33\7\"\2\2\32\31\3\2\2\2\33\34\3\2\2\2\34\32\3")
        buf.write("\2\2\2\34\35\3\2\2\2\35\4\3\2\2\2\36 \t\2\2\2\37\36\3")
        buf.write("\2\2\2 #\3\2\2\2!\37\3\2\2\2!\"\3\2\2\2\"\'\3\2\2\2#!")
        buf.write("\3\2\2\2$&\7\60\2\2%$\3\2\2\2&)\3\2\2\2\'%\3\2\2\2\'(")
        buf.write("\3\2\2\2(+\3\2\2\2)\'\3\2\2\2*,\t\2\2\2+*\3\2\2\2,-\3")
        buf.write("\2\2\2-+\3\2\2\2-.\3\2\2\2.\6\3\2\2\2/\61\t\3\2\2\60/")
        buf.write("\3\2\2\2\61\62\3\2\2\2\62\60\3\2\2\2\62\63\3\2\2\2\63")
        buf.write("\b\3\2\2\2\648\t\4\2\2\65\67\13\2\2\2\66\65\3\2\2\2\67")
        buf.write(":\3\2\2\289\3\2\2\28\66\3\2\2\29\n\3\2\2\2:8\3\2\2\2;")
        buf.write("<\7]\2\2<=\7N\2\2=>\7Q\2\2>?\7C\2\2?@\7F\2\2@A\7K\2\2")
        buf.write("AB\7P\2\2BC\7I\2\2CD\7U\2\2DE\7_\2\2E\f\3\2\2\2FH\13\2")
        buf.write("\2\2GF\3\2\2\2HK\3\2\2\2IJ\3\2\2\2IG\3\2\2\2JL\3\2\2\2")
        buf.write("KI\3\2\2\2LM\5\13\6\2MN\3\2\2\2NO\b\7\2\2O\16\3\2\2\2")
        buf.write("PQ\7]\2\2QR\5\t\5\2RV\7_\2\2SU\13\2\2\2TS\3\2\2\2UX\3")
        buf.write("\2\2\2VW\3\2\2\2VT\3\2\2\2WY\3\2\2\2XV\3\2\2\2YZ\b\b\2")
        buf.write("\2Z\20\3\2\2\2[_\7=\2\2\\^\13\2\2\2]\\\3\2\2\2^a\3\2\2")
        buf.write("\2_`\3\2\2\2_]\3\2\2\2`b\3\2\2\2a_\3\2\2\2bc\5\25\13\2")
        buf.write("cd\3\2\2\2de\b\t\2\2e\22\3\2\2\2fj\7=\2\2gi\13\2\2\2h")
        buf.write("g\3\2\2\2il\3\2\2\2jk\3\2\2\2jh\3\2\2\2km\3\2\2\2lj\3")
        buf.write("\2\2\2mn\5\3\2\2no\3\2\2\2op\b\n\2\2p\24\3\2\2\2qs\t\5")
        buf.write("\2\2rq\3\2\2\2st\3\2\2\2tr\3\2\2\2tu\3\2\2\2uv\3\2\2\2")
        buf.write("vw\b\13\2\2w\26\3\2\2\2xz\t\6\2\2yx\3\2\2\2z{\3\2\2\2")
        buf.write("{y\3\2\2\2{|\3\2\2\2|}\3\2\2\2}~\b\f\2\2~\30\3\2\2\2\17")
        buf.write("\2\34!\'-\628IV_jt{\3\b\2\2")
        return buf.getvalue()


class subcatchmentsLexer(Lexer):

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    ANY_SPACE = 1
    VALUE = 2
    ID = 3
    CAPITALS = 4
    LOADINGS_HEADER = 5
    PRELOADINGS = 6
    POSTLOADINGS = 7
    COMMENT = 8
    COMMENTSP = 9
    NEWLINES = 10
    WS = 11

    channelNames = [ u"DEFAULT_TOKEN_CHANNEL", u"HIDDEN" ]

    modeNames = [ "DEFAULT_MODE" ]

    literalNames = [ "<INVALID>",
            "'[LOADINGS]'" ]

    symbolicNames = [ "<INVALID>",
            "ANY_SPACE", "VALUE", "ID", "CAPITALS", "LOADINGS_HEADER", "PRELOADINGS", 
            "POSTLOADINGS", "COMMENT", "COMMENTSP", "NEWLINES", "WS" ]

    ruleNames = [ "ANY_SPACE", "VALUE", "ID", "CAPITALS", "LOADINGS_HEADER", 
                  "PRELOADINGS", "POSTLOADINGS", "COMMENT", "COMMENTSP", 
                  "NEWLINES", "WS" ]

    grammarFileName = "subcatchments.g4"

    def __init__(self, input=None, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.9.2")
        self._interp = LexerATNSimulator(self, self.atn, self.decisionsToDFA, PredictionContextCache())
        self._actions = None
        self._predicates = None


