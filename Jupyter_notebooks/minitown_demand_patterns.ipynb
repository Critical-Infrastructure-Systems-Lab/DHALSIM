{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load module\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import wntr\n",
    "import wntr_utils\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from random import shuffle\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook to generate random demand patterns and tank initial conditions for Minitorn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'second_batch_three_year_demands_minitown.csv'\n",
    "random_init_points = 'second_batch_random_init_points.csv'\n",
    "random_initial_tanks = 'second_batch_minitown_tank_initial_conditions.csv'\n",
    "all_data_path = '../Demand_patterns/data/allData.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load STREaM data (STREaM is a simulator of end-uses and water demand patterns)\n",
    "# This dataset contains 3 years of hourly (26280 data points) synthetic demand data \n",
    "# for 4 user_classes = ['low','average','high','morning','night']. There are 500 user for each class,\n",
    "# with the first 10 users having leaks. We need to remove these users for our purposes. \n",
    "df = pd.read_csv(all_data_path, header=None)\n",
    "# \n",
    "# create headers\n",
    "user_classes = ['low','average','high','morning','night']\n",
    "headers = []\n",
    "for user_class in user_classes:\n",
    "    suffixes = (('_'+user_class+' ')*400).split() # original\n",
    "    for suffix, number in zip(suffixes,range(1,401)):\n",
    "        headers.append('user'+suffix+'_'+'%03d'%number)  \n",
    "        \n",
    "# reverse df and change df columns\n",
    "df = df.T\n",
    "df.columns = headers\n",
    "\n",
    "# remove first 10 of each class (these have leaks, so not useful for our purposes)\n",
    "users_to_remove = np.array(headers).reshape(-1,10)[::40].ravel().tolist()\n",
    "df.drop(users_to_remove, axis = 1, inplace = True)\n",
    "headers = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function creates a hourly pattern of multipliers (up to 26280 hours long) mixing together n (max 1950) patterns\n",
    "# from the STREaM dataset; it scales within a range (as expected for WNTR/EPANET input)\n",
    "def create_demand_pattern(df_patterns, n_hours=168, n_mix=50, bound = [0.3,0.9], noise_intensity=0.01):\n",
    "    cols =df_patterns.columns.to_list()\n",
    "    shuffle(cols)\n",
    "    df_patterns = df_patterns[cols]\n",
    "    s = MinMaxScaler(bound)\n",
    "    temp=np.squeeze(s.fit_transform(df_patterns.iloc[:n_hours,:n_mix].mean(axis=1).values.reshape(-1,1)))\n",
    "    dem_pat = temp + np.random.randn(n_hours)*noise_intensity\n",
    "    return dem_pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andres\\anaconda3\\lib\\site-packages\\wntr\\epanet\\io.py:2173: UserWarning: Not all curves were used in \"minitown_map.inp\"; added with type None, units conversion left to user\n",
      "  warnings.warn('Not all curves were used in \"{}\"; added with type None, units conversion left to user'.format(self.wn.name))\n"
     ]
    }
   ],
   "source": [
    "# load EPANET model\n",
    "inp_file = 'minitown_map.inp'\n",
    "wn = wntr.network.WaterNetworkModel(inp_file)\n",
    "\n",
    "# save original patterns\n",
    "names, patterns =[],[]\n",
    "for name, pat in wn.patterns():\n",
    "    names.append(name)\n",
    "    patterns.append(pat.multipliers)\n",
    "df_pat_orig = pd.DataFrame(data = patterns).T\n",
    "df_pat_orig.columns = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 3-year pattern for the District Metered Area (DMA)\n",
    "names, patterns =[],[]\n",
    "for name, pat in wn.patterns():\n",
    "    names.append(name)\n",
    "    temp = create_demand_pattern(df, n_hours=24*365*3, n_mix=150)\n",
    "    pat.multipliers = temp\n",
    "    patterns.append(pat.multipliers)\n",
    "df_pat_new = pd.DataFrame(data = patterns).T\n",
    "df_pat_new.columns = names\n",
    "df_pat_new.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    start\n",
      "0    6060\n",
      "1    6491\n",
      "2   17176\n",
      "3    7355\n",
      "4    2145\n",
      "5   24171\n",
      "6   15602\n",
      "7   23229\n",
      "8   20317\n",
      "9   23187\n",
      "10  10731\n",
      "11  25477\n",
      "12  19504\n",
      "13   4600\n",
      "14  11212\n",
      "15  15349\n",
      "16  23572\n",
      "17  14688\n",
      "18  17251\n",
      "19  19700\n",
      "20  15704\n",
      "21  17657\n",
      "22  17680\n",
      "23   9999\n",
      "24  10621\n",
      "25  25252\n",
      "26   2460\n",
      "27   6396\n",
      "28  13197\n",
      "29  17673\n",
      "30  20859\n",
      "31   3647\n",
      "32  23095\n",
      "33  14965\n",
      "34  12010\n",
      "35  15192\n",
      "36   7480\n",
      "37  16556\n"
     ]
    }
   ],
   "source": [
    "# Create a pandas dataframe with columns = each DMA pattern and 38 random initial pattern values\n",
    "df_pat_new = pd.read_csv(output_file)\n",
    "values=[]\n",
    "weekly_simulation_duration = 168\n",
    "ten_days_simulatino_duration = 240\n",
    "weekly=False\n",
    "\n",
    "if weekly:\n",
    "    limit = weekly_simulation_duration\n",
    "else:\n",
    "    limit = ten_days_simulatino_duration\n",
    "\n",
    "for i in range(0,38):\n",
    "    value = random.randint(0, len(df_pat_new)-limit)        \n",
    "    values.append(value)\n",
    "pattern_random_init_point = pd.DataFrame(data = values)\n",
    "pattern_random_init_point.columns = ['start']\n",
    "print(pattern_random_init_point)\n",
    "pattern_random_init_point.to_csv(random_init_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TANK\n",
      "0   4.803270\n",
      "1   4.850546\n",
      "2   2.642841\n",
      "3   4.779293\n",
      "4   3.682787\n",
      "5   3.486859\n",
      "6   2.764002\n",
      "7   3.002364\n",
      "8   3.119228\n",
      "9   4.094907\n",
      "10  4.948651\n",
      "11  1.069782\n",
      "12  2.371399\n",
      "13  0.936612\n",
      "14  2.608917\n",
      "15  5.116737\n",
      "16  2.637573\n",
      "17  0.872869\n",
      "18  2.508483\n",
      "19  2.925417\n",
      "20  3.275713\n",
      "21  4.508348\n",
      "22  1.791803\n",
      "23  5.002481\n",
      "24  3.872937\n",
      "25  3.988391\n",
      "26  3.657865\n",
      "27  1.797437\n",
      "28  2.857792\n",
      "29  4.676100\n",
      "30  1.555085\n",
      "31  1.093595\n",
      "32  1.221103\n",
      "33  3.286744\n",
      "34  4.833495\n",
      "35  4.405051\n",
      "36  2.238449\n",
      "37  2.970209\n"
     ]
    }
   ],
   "source": [
    "# Create a pandas dataframe with initial tank levels for the 7 C-Town tanks and 38 weeks\n",
    "values=[]\n",
    "#tank_names = ['T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7']\n",
    "tank_names = ['TANK']\n",
    "for name in tank_names:\n",
    "    aux=[]\n",
    "    for i in range(0,38):\n",
    "        tank_max_value = wn.get_node(name).max_level\n",
    "        min_value = tank_max_value*0.10\n",
    "        max_value = tank_max_value*0.80\n",
    "        value = random.uniform(min_value, max_value)        \n",
    "        aux.append(value)\n",
    "    values.append(aux)\n",
    "tank_initial_levels = pd.DataFrame(data = values).T\n",
    "tank_initial_levels.columns = tank_names\n",
    "print(tank_initial_levels)\n",
    "tank_initial_levels.to_csv(random_initial_tanks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
